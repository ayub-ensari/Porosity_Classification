{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning\n",
    "## Part 3: Best Model architecture and hyperparameters\n",
    "\n",
    "> We have experimented with six different archiectures of CNN and a range of hyperparameters and their values. Here, we will build six models based on the best hyperparameters. Finally, we will decide on the best model architectuer and the values of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from os import walk\n",
    "import time\n",
    "import regex as re\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU device: /device:GPU:0\n",
      "Num Devices Available:  2\n",
      "Num CPUs Available:  1\n",
      "Num GPUs Available:  1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18396885793463053931\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2909195470\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14621236913820412343\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn(\"No GPU found\")\n",
    "else:\n",
    "    print(\"Default GPU device: {}\".format(tf.test.gpu_device_name()))\n",
    "    \n",
    "print(\"Num Devices Available: \", len(tf.config.experimental.list_physical_devices()))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Hypyer parameter values from Text Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Basic Model 1c1p1f1d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30 30 30 30\n",
      "(30, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conv1_filters</th>\n",
       "      <th>Conv1_kernel</th>\n",
       "      <th>Conv1_activation</th>\n",
       "      <th>Maxpol_stride</th>\n",
       "      <th>Dense1_units</th>\n",
       "      <th>Dense1_activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9823911190032959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9740500450134277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9684893488883972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9684893488883972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9684893488883972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>160</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9675625562667847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.960148274898529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9564411640167236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9527339935302734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.949026882648468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Conv1_filters Conv1_kernel Conv1_activation Maxpol_stride Dense1_units  \\\n",
       "0            64            7             relu             2          160   \n",
       "1            64            5             relu             2          160   \n",
       "2            64            7             relu             8          224   \n",
       "3            64            3             tanh             2          224   \n",
       "4            96            7             relu             8          224   \n",
       "5            48            7             tanh            10          160   \n",
       "6            96            7             relu             8          224   \n",
       "7            48            5              elu             4          160   \n",
       "8            64            5             relu             2          160   \n",
       "9            64            7             relu             8          224   \n",
       "\n",
       "  Dense1_activation learning_rate               Score  \n",
       "0              relu          0.01  0.9823911190032959  \n",
       "1              relu        0.0001  0.9740500450134277  \n",
       "2              relu          0.01  0.9684893488883972  \n",
       "3              relu          0.01  0.9684893488883972  \n",
       "4              tanh        0.0001  0.9684893488883972  \n",
       "5              tanh         0.001  0.9675625562667847  \n",
       "6              tanh        0.0001   0.960148274898529  \n",
       "7              relu         0.001  0.9564411640167236  \n",
       "8              relu        0.0001  0.9527339935302734  \n",
       "9              relu          0.01   0.949026882648468  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1_filter = []\n",
    "conv_1_kernel = []\n",
    "activation_1_conv = []\n",
    "MaxPol_1_stride = []\n",
    "dense_1_units = []\n",
    "activation_1_dense = []\n",
    "learning_rate = []\n",
    "Score = []\n",
    "############ Reading text file\n",
    "with open('./Hyperparameter_Files/1c1p1f1d1d.txt') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "########### iterating over lines and saving hyper parameters  \n",
    "for line in lines:\n",
    "    if 'conv_1_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_filter.append(line.split()[1])\n",
    "    elif'conv_1_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_kernel.append(line.split()[1])\n",
    "    elif'activation_1_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_conv.append(line.split()[1])\n",
    "    elif'MaxPol_1_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_1_stride.append(line.split()[1])\n",
    "    elif'dense_1_units' in line:\n",
    "        #print(line.split()[1])\n",
    "        dense_1_units.append(line.split()[1])\n",
    "    elif'activation_1_dense' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_dense.append(line.split()[1])\n",
    "    elif'learning_rate' in line:\n",
    "        #print(line.split()[1])\n",
    "        learning_rate.append(line.split()[1])\n",
    "    elif'Score' in line:\n",
    "        #print(line.split()[1])\n",
    "        Score.append(line.split()[1])\n",
    "############# Checking the consistency of the parameters\n",
    "print(len(conv_1_filter), len(conv_1_kernel), len(activation_1_conv), len(MaxPol_1_stride), len(dense_1_units), \n",
    "      len(activation_1_dense), len(learning_rate), len(Score))\n",
    "\n",
    "############# create data frame\n",
    "df_1c1p1f1d1d = pd.DataFrame(list(zip(conv_1_filter, conv_1_kernel, activation_1_conv, MaxPol_1_stride,\n",
    "                                      dense_1_units, activation_1_dense, learning_rate, Score)),\n",
    "               columns =['Conv1_filters', 'Conv1_kernel', 'Conv1_activation','Maxpol_stride',\n",
    "                         'Dense1_units', 'Dense1_activation', 'learning_rate','Score'])\n",
    "############ Df head\n",
    "print(df_1c1p1f1d1d.shape)\n",
    "df_1c1p1f1d1d.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model 1c1p1f2d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30 30 30 30 30 30\n",
      "(30, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conv1_filters</th>\n",
       "      <th>Conv1_kernel</th>\n",
       "      <th>Conv1_activation</th>\n",
       "      <th>Maxpol_stride</th>\n",
       "      <th>Dense1_units</th>\n",
       "      <th>Dense1_activation</th>\n",
       "      <th>Dense2_units</th>\n",
       "      <th>Dense2_activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9777571558952332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9768304228782654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>6</td>\n",
       "      <td>160</td>\n",
       "      <td>tanh</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9759036302566528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9740500450134277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>160</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.958294689655304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9564411640167236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>tanh</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.949026882648468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>160</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9416126012802124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>12</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9388322234153748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>tanh</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9369786977767944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Conv1_filters Conv1_kernel Conv1_activation Maxpol_stride Dense1_units  \\\n",
       "0            64            7             relu             2          160   \n",
       "1            48            7             relu             8          160   \n",
       "2            64            5              elu             6          160   \n",
       "3            48            7             relu             8          160   \n",
       "4            96            3              elu             8          224   \n",
       "5            48            7             relu             8          160   \n",
       "6            32            5             tanh            10           96   \n",
       "7            96            3              elu             8          224   \n",
       "8            96            5              elu            12          160   \n",
       "9            32            5             tanh            10           96   \n",
       "\n",
       "  Dense1_activation Dense2_units Dense2_activation learning_rate  \\\n",
       "0              relu          224              tanh         0.001   \n",
       "1              relu           32              tanh         0.001   \n",
       "2              tanh          224              tanh        0.0001   \n",
       "3              relu           32              tanh         0.001   \n",
       "4              tanh          160              tanh        0.0001   \n",
       "5              relu           32              tanh         0.001   \n",
       "6              tanh           96              relu         0.001   \n",
       "7              tanh          160              tanh        0.0001   \n",
       "8              relu          160              relu        0.0001   \n",
       "9              tanh           96              relu         0.001   \n",
       "\n",
       "                Score  \n",
       "0  0.9777571558952332  \n",
       "1  0.9768304228782654  \n",
       "2  0.9759036302566528  \n",
       "3  0.9740500450134277  \n",
       "4   0.958294689655304  \n",
       "5  0.9564411640167236  \n",
       "6   0.949026882648468  \n",
       "7  0.9416126012802124  \n",
       "8  0.9388322234153748  \n",
       "9  0.9369786977767944  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1_filter = []\n",
    "conv_1_kernel = []\n",
    "activation_1_conv = []\n",
    "MaxPol_1_stride = []\n",
    "dense_1_units = []\n",
    "activation_1_dense = []\n",
    "dense_2_units = []\n",
    "activation_2_dense = []\n",
    "learning_rate = []\n",
    "Score = []\n",
    "############ Reading text file\n",
    "with open('./Hyperparameter_Files/1c1p1f2d1d.txt') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "########### iterating over lines and saving hyper parameters  \n",
    "for line in lines:\n",
    "    if 'conv_1_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_filter.append(line.split()[1])\n",
    "    elif'conv_1_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_kernel.append(line.split()[1])\n",
    "    elif'activation_1_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_conv.append(line.split()[1])\n",
    "    elif'MaxPol_1_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_1_stride.append(line.split()[1])\n",
    "    elif'dense_1_units' in line:\n",
    "        #print(line.split()[1])\n",
    "        dense_1_units.append(line.split()[1])\n",
    "    elif'activation_1_dense' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_dense.append(line.split()[1])\n",
    "    elif'dense_2_units' in line:\n",
    "        #print(line.split()[1])\n",
    "        dense_2_units.append(line.split()[1])\n",
    "    elif'activation_2_dense' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_2_dense.append(line.split()[1])\n",
    "    elif'learning_rate' in line:\n",
    "        #print(line.split()[1])\n",
    "        learning_rate.append(line.split()[1])\n",
    "    elif'Score' in line:\n",
    "        #print(line.split()[1])\n",
    "        Score.append(line.split()[1])\n",
    "############# Checking the consistency of the parameters\n",
    "print(len(conv_1_filter), len(conv_1_kernel), len(activation_1_conv), len(MaxPol_1_stride), len(dense_1_units), \n",
    "      len(activation_1_dense),len(dense_2_units), len(activation_2_dense), len(learning_rate), len(Score))\n",
    "\n",
    "############# create data frame\n",
    "df_1c1p1f2d1d = pd.DataFrame(list(zip(conv_1_filter, conv_1_kernel, activation_1_conv, MaxPol_1_stride,\n",
    "                                      dense_1_units, activation_1_dense, dense_2_units, activation_2_dense,\n",
    "                                      learning_rate, Score)),\n",
    "               columns =['Conv1_filters', 'Conv1_kernel', 'Conv1_activation','Maxpol_stride',\n",
    "                         'Dense1_units', 'Dense1_activation','Dense2_units', 'Dense2_activation', \n",
    "                         'learning_rate','Score'])\n",
    "############ Df head\n",
    "print(df_1c1p1f2d1d.shape)\n",
    "df_1c1p1f2d1d.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Basic Model 2c2p1f1d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30 30 30 30 30 30 30 30\n",
      "(30, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conv1_filters</th>\n",
       "      <th>Conv1_kernel</th>\n",
       "      <th>Conv1_activation</th>\n",
       "      <th>Maxpol1_stride</th>\n",
       "      <th>Conv2_filters</th>\n",
       "      <th>Conv2_kernel</th>\n",
       "      <th>Conv2_activation</th>\n",
       "      <th>Maxpol2_stride</th>\n",
       "      <th>Dense1_units</th>\n",
       "      <th>Dense1_activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9805375337600708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9731232523918152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>160</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9721964597702026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>elu</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9684893488883972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>6</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9666357636451721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>160</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9620018601417542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>elu</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9564411640167236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>elu</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9471732974052429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9462465047836304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>elu</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9341983199119568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Conv1_filters Conv1_kernel Conv1_activation Maxpol1_stride Conv2_filters  \\\n",
       "0            32            7             relu              6            80   \n",
       "1            96            3             tanh              4            96   \n",
       "2            64            7             relu              2            48   \n",
       "3            80            7              elu              6            64   \n",
       "4            80            5             relu              8            64   \n",
       "5            64            7             relu              2            48   \n",
       "6            80            7              elu              6            96   \n",
       "7            80            7              elu              6            64   \n",
       "8            96            5              elu              2            80   \n",
       "9            48            7              elu              8            64   \n",
       "\n",
       "  Conv2_kernel Conv2_activation Maxpol2_stride Dense1_units Dense1_activation  \\\n",
       "0            5             tanh              4          224              tanh   \n",
       "1            3             relu              4          224              tanh   \n",
       "2            7             tanh             10          160              tanh   \n",
       "3            5             tanh              4          224              tanh   \n",
       "4            5              elu              6          224              tanh   \n",
       "5            7             tanh             10          160              tanh   \n",
       "6            7             tanh             10           96              relu   \n",
       "7            5             tanh              4          224              tanh   \n",
       "8            7             relu             10          160              relu   \n",
       "9            7             relu              8          224              relu   \n",
       "\n",
       "  learning_rate               Score  \n",
       "0         0.001  0.9805375337600708  \n",
       "1        0.0001  0.9731232523918152  \n",
       "2         0.001  0.9721964597702026  \n",
       "3        0.0001  0.9684893488883972  \n",
       "4        0.0001  0.9666357636451721  \n",
       "5         0.001  0.9620018601417542  \n",
       "6          0.01  0.9564411640167236  \n",
       "7        0.0001  0.9471732974052429  \n",
       "8          0.01  0.9462465047836304  \n",
       "9          0.01  0.9341983199119568  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1_filter = []\n",
    "conv_1_kernel = []\n",
    "activation_1_conv = []\n",
    "MaxPol_1_stride = []\n",
    "conv_2_filter = []\n",
    "conv_2_kernel = []\n",
    "activation_2_conv = []\n",
    "MaxPol_2_stride = []\n",
    "dense_1_units = []\n",
    "activation_1_dense = []\n",
    "learning_rate = []\n",
    "Score = []\n",
    "############ Reading text file\n",
    "with open('./Hyperparameter_Files/2c2p1f1d1d.txt') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "########### iterating over lines and saving hyper parameters  \n",
    "for line in lines:\n",
    "    if 'conv_1_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_filter.append(line.split()[1])\n",
    "    elif'conv_1_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_kernel.append(line.split()[1])\n",
    "    elif'activation_1_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_conv.append(line.split()[1])\n",
    "    elif'MaxPol_1_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_1_stride.append(line.split()[1])\n",
    "    elif 'conv_2_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_2_filter.append(line.split()[1])\n",
    "    elif'conv_2_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_2_kernel.append(line.split()[1])\n",
    "    elif'activation_2_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_2_conv.append(line.split()[1])\n",
    "    elif'MaxPol_2_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_2_stride.append(line.split()[1])\n",
    "    elif'dense_1_units' in line:\n",
    "        #print(line.split()[1])\n",
    "        dense_1_units.append(line.split()[1])\n",
    "    elif'activation_1_dense' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_dense.append(line.split()[1])\n",
    "    elif'learning_rate' in line:\n",
    "        #print(line.split()[1])\n",
    "        learning_rate.append(line.split()[1])\n",
    "    elif'Score' in line:\n",
    "        #print(line.split()[1])\n",
    "        Score.append(line.split()[1])\n",
    "############# Checking the consistency of the parameters\n",
    "print(len(conv_1_filter), len(conv_1_kernel), len(activation_1_conv), len(MaxPol_1_stride),\n",
    "      len(conv_2_filter), len(conv_2_kernel), len(activation_2_conv), len(MaxPol_2_stride), \n",
    "      len(dense_1_units), len(activation_1_dense), len(learning_rate), len(Score))\n",
    "\n",
    "############# create data frame\n",
    "df_2c2p1f1d1d = pd.DataFrame(list(zip(conv_1_filter, conv_1_kernel, activation_1_conv, MaxPol_1_stride,\n",
    "                                      conv_2_filter, conv_2_kernel, activation_2_conv, MaxPol_2_stride,\n",
    "                                      dense_1_units, activation_1_dense, learning_rate, Score)),\n",
    "               columns =['Conv1_filters', 'Conv1_kernel', 'Conv1_activation','Maxpol1_stride',\n",
    "                         'Conv2_filters', 'Conv2_kernel', 'Conv2_activation','Maxpol2_stride',\n",
    "                         'Dense1_units', 'Dense1_activation', 'learning_rate','Score'])\n",
    "############ Df head\n",
    "print(df_2c2p1f1d1d.shape)\n",
    "df_2c2p1f1d1d.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4)  Basic Model 2c2p1f2d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      "(30, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conv1_filters</th>\n",
       "      <th>Conv1_kernel</th>\n",
       "      <th>Conv1_activation</th>\n",
       "      <th>Maxpol1_stride</th>\n",
       "      <th>Conv2_filters</th>\n",
       "      <th>Conv2_kernel</th>\n",
       "      <th>Conv2_activation</th>\n",
       "      <th>Maxpol2_stride</th>\n",
       "      <th>Dense1_units</th>\n",
       "      <th>Dense1_activation</th>\n",
       "      <th>Dense2_units</th>\n",
       "      <th>Dense2_activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>tanh</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>tanh</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9759036302566528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>96</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9749768376350403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>tanh</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>tanh</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9740500450134277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>160</td>\n",
       "      <td>tanh</td>\n",
       "      <td>224</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9731232523918152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>96</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9684893488883972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9666357636451721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9629286527633667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>160</td>\n",
       "      <td>tanh</td>\n",
       "      <td>224</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9610750675201416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9610750675201416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>tanh</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.960148274898529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Conv1_filters Conv1_kernel Conv1_activation Maxpol1_stride Conv2_filters  \\\n",
       "0            48            3             relu              2            48   \n",
       "1            64            5             relu              6            48   \n",
       "2            48            3             relu              2            48   \n",
       "3            64            7             relu              2            48   \n",
       "4            64            5             relu              6            48   \n",
       "5            48            7             relu              6            80   \n",
       "6            32            5              elu              6            32   \n",
       "7            64            7             relu              2            48   \n",
       "8            48            7             relu              6            80   \n",
       "9            48            3              elu              2            80   \n",
       "\n",
       "  Conv2_kernel Conv2_activation Maxpol2_stride Dense1_units Dense1_activation  \\\n",
       "0            7             tanh              6           96              tanh   \n",
       "1            5             tanh              2          160              relu   \n",
       "2            7             tanh              6           96              tanh   \n",
       "3            7             tanh             10          160              tanh   \n",
       "4            5             tanh              2          160              relu   \n",
       "5            5             tanh              6           96              relu   \n",
       "6            3             tanh              4          160              relu   \n",
       "7            7             tanh             10          160              tanh   \n",
       "8            5             tanh              6           96              relu   \n",
       "9            3             tanh              4          160              tanh   \n",
       "\n",
       "  Dense2_units Dense2_activation learning_rate               Score  \n",
       "0           96              relu         0.001  0.9759036302566528  \n",
       "1           96              tanh         0.001  0.9749768376350403  \n",
       "2           96              relu         0.001  0.9740500450134277  \n",
       "3          224              relu         0.001  0.9731232523918152  \n",
       "4           96              tanh         0.001  0.9684893488883972  \n",
       "5           32              relu          0.01  0.9666357636451721  \n",
       "6           96              relu        0.0001  0.9629286527633667  \n",
       "7          224              relu         0.001  0.9610750675201416  \n",
       "8           32              relu          0.01  0.9610750675201416  \n",
       "9          160              relu        0.0001   0.960148274898529  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1_filter = []\n",
    "conv_1_kernel = []\n",
    "activation_1_conv = []\n",
    "MaxPol_1_stride = []\n",
    "conv_2_filter = []\n",
    "conv_2_kernel = []\n",
    "activation_2_conv = []\n",
    "MaxPol_2_stride = []\n",
    "dense_1_units = []\n",
    "activation_1_dense = []\n",
    "dense_2_units = []\n",
    "activation_2_dense = []\n",
    "learning_rate = []\n",
    "Score = []\n",
    "############ Reading text file\n",
    "with open('./Hyperparameter_Files/2c2p1f2d1d.txt') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "########### iterating over lines and saving hyper parameters  \n",
    "for line in lines:\n",
    "    if 'conv_1_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_filter.append(line.split()[1])\n",
    "    elif'conv_1_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_kernel.append(line.split()[1])\n",
    "    elif'activation_1_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_conv.append(line.split()[1])\n",
    "    elif'MaxPol_1_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_1_stride.append(line.split()[1])\n",
    "    elif 'conv_2_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_2_filter.append(line.split()[1])\n",
    "    elif'conv_2_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_2_kernel.append(line.split()[1])\n",
    "    elif'activation_2_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_2_conv.append(line.split()[1])\n",
    "    elif'MaxPol_2_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_2_stride.append(line.split()[1])\n",
    "    elif'dense_1_units' in line:\n",
    "        #print(line.split()[1])\n",
    "        dense_1_units.append(line.split()[1])\n",
    "    elif'activation_1_dense' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_dense.append(line.split()[1])\n",
    "    elif'dense_2_units' in line:\n",
    "        #print(line.split()[1])\n",
    "        dense_2_units.append(line.split()[1])\n",
    "    elif'activation_2_dense' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_2_dense.append(line.split()[1])\n",
    "    elif'learning_rate' in line:\n",
    "        #print(line.split()[1])\n",
    "        learning_rate.append(line.split()[1])\n",
    "    elif'Score' in line:\n",
    "        #print(line.split()[1])\n",
    "        Score.append(line.split()[1])\n",
    "############# Checking the consistency of the parameters\n",
    "print(len(conv_1_filter), len(conv_1_kernel), len(activation_1_conv), len(MaxPol_1_stride),\n",
    "      len(conv_2_filter), len(conv_2_kernel), len(activation_2_conv), len(MaxPol_2_stride), \n",
    "      len(dense_1_units), len(activation_1_dense), \n",
    "      len(dense_2_units), len(activation_2_dense),\n",
    "      len(learning_rate), len(Score))\n",
    "\n",
    "############# create data frame\n",
    "df_2c2p1f2d1d = pd.DataFrame(list(zip(conv_1_filter, conv_1_kernel, activation_1_conv, MaxPol_1_stride,\n",
    "                                      conv_2_filter, conv_2_kernel, activation_2_conv, MaxPol_2_stride,\n",
    "                                      dense_1_units, activation_1_dense, \n",
    "                                      dense_2_units, activation_2_dense,\n",
    "                                      learning_rate, Score)),\n",
    "               columns =['Conv1_filters', 'Conv1_kernel', 'Conv1_activation','Maxpol1_stride',\n",
    "                         'Conv2_filters', 'Conv2_kernel', 'Conv2_activation','Maxpol2_stride',\n",
    "                         'Dense1_units', 'Dense1_activation',\n",
    "                         'Dense2_units', 'Dense2_activation',\n",
    "                         'learning_rate','Score'])\n",
    "############ Df head\n",
    "print(df_2c2p1f2d1d.shape)\n",
    "df_2c2p1f2d1d.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5)  Basic Model 3c3p1f1d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      "(30, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conv1_filters</th>\n",
       "      <th>Conv1_kernel</th>\n",
       "      <th>Conv1_activation</th>\n",
       "      <th>Maxpol1_stride</th>\n",
       "      <th>Conv2_filters</th>\n",
       "      <th>Conv2_kernel</th>\n",
       "      <th>Conv2_activation</th>\n",
       "      <th>Maxpol2_stride</th>\n",
       "      <th>Conv3_filters</th>\n",
       "      <th>Conv3_kernel</th>\n",
       "      <th>Conv3_activation</th>\n",
       "      <th>Maxpol3_stride</th>\n",
       "      <th>Dense1_units</th>\n",
       "      <th>Dense1_activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9796107411384583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9786839485168457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9777571558952332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9749768376350403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9731232523918152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9703429341316223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9703429341316223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9694161415100098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9675625562667847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9675625562667847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Conv1_filters Conv1_kernel Conv1_activation Maxpol1_stride Conv2_filters  \\\n",
       "0            64            3             relu              2            32   \n",
       "1            64            7              elu              2            80   \n",
       "2            80            3             relu              2            80   \n",
       "3            64            7             relu              6            32   \n",
       "4            32           11             relu              8            48   \n",
       "5            32           11             relu              8            48   \n",
       "6            64            3             relu              2            32   \n",
       "7            80           11             relu              2            64   \n",
       "8            64            7             relu              6            32   \n",
       "9            32            5              elu              4            48   \n",
       "\n",
       "  Conv2_kernel Conv2_activation Maxpol2_stride Conv3_filters Conv3_kernel  \\\n",
       "0            5             tanh              4            80            3   \n",
       "1            5             tanh              2            48            2   \n",
       "2            5             relu              2            64            2   \n",
       "3            3             relu              4            80            3   \n",
       "4            5              elu              4            48            2   \n",
       "5            5              elu              4            48            2   \n",
       "6            5             tanh              4            80            3   \n",
       "7            5             relu              4            64            2   \n",
       "8            3             relu              4            80            3   \n",
       "9            5             relu              4            64            2   \n",
       "\n",
       "  Conv3_activation Maxpol3_stride Dense1_units Dense1_activation  \\\n",
       "0             tanh              2          224              tanh   \n",
       "1             relu              2          224              tanh   \n",
       "2             relu              2          224              tanh   \n",
       "3              elu              2           96              relu   \n",
       "4              elu              2          224              tanh   \n",
       "5              elu              2          224              tanh   \n",
       "6             tanh              2          224              tanh   \n",
       "7              elu              2           96              relu   \n",
       "8              elu              2           96              relu   \n",
       "9              elu              2           96              relu   \n",
       "\n",
       "  learning_rate               Score  \n",
       "0        0.0001  0.9796107411384583  \n",
       "1        0.0001  0.9786839485168457  \n",
       "2        0.0001  0.9777571558952332  \n",
       "3         0.001  0.9749768376350403  \n",
       "4         0.001  0.9731232523918152  \n",
       "5         0.001  0.9703429341316223  \n",
       "6        0.0001  0.9703429341316223  \n",
       "7         0.001  0.9694161415100098  \n",
       "8         0.001  0.9675625562667847  \n",
       "9        0.0001  0.9675625562667847  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1_filter = []\n",
    "conv_1_kernel = []\n",
    "activation_1_conv = []\n",
    "MaxPol_1_stride = []\n",
    "conv_2_filter = []\n",
    "conv_2_kernel = []\n",
    "activation_2_conv = []\n",
    "MaxPol_2_stride = []\n",
    "conv_3_filter = []\n",
    "conv_3_kernel = []\n",
    "activation_3_conv = []\n",
    "MaxPol_3_stride = []\n",
    "dense_1_units = []\n",
    "activation_1_dense = []\n",
    "learning_rate = []\n",
    "Score = []\n",
    "############ Reading text file\n",
    "with open('./Hyperparameter_Files/3c3p1f1d1d.txt') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "########### iterating over lines and saving hyper parameters  \n",
    "for line in lines:\n",
    "    if 'conv_1_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_filter.append(line.split()[1])\n",
    "    elif'conv_1_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_kernel.append(line.split()[1])\n",
    "    elif'activation_1_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_conv.append(line.split()[1])\n",
    "    elif'MaxPol_1_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_1_stride.append(line.split()[1])\n",
    "    elif 'conv_2_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_2_filter.append(line.split()[1])\n",
    "    elif'conv_2_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_2_kernel.append(line.split()[1])\n",
    "    elif'activation_2_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_2_conv.append(line.split()[1])\n",
    "    elif'MaxPol_2_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_2_stride.append(line.split()[1])\n",
    "    elif 'conv_3_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_3_filter.append(line.split()[1])\n",
    "    elif'conv_3_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_3_kernel.append(line.split()[1])\n",
    "    elif'activation_3_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_3_conv.append(line.split()[1])\n",
    "    elif'MaxPol_3_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_3_stride.append(line.split()[1])\n",
    "    elif'dense_1_units' in line:\n",
    "        #print(line.split()[1])\n",
    "        dense_1_units.append(line.split()[1])\n",
    "    elif'activation_1_dense' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_dense.append(line.split()[1])\n",
    "    elif'learning_rate' in line:\n",
    "        #print(line.split()[1])\n",
    "        learning_rate.append(line.split()[1])\n",
    "    elif'Score' in line:\n",
    "        #print(line.split()[1])\n",
    "        Score.append(line.split()[1])\n",
    "############# Checking the consistency of the parameters\n",
    "print(len(conv_1_filter), len(conv_1_kernel), len(activation_1_conv), len(MaxPol_1_stride),\n",
    "      len(conv_2_filter), len(conv_2_kernel), len(activation_2_conv), len(MaxPol_2_stride),\n",
    "      len(conv_3_filter), len(conv_3_kernel), len(activation_3_conv), len(MaxPol_3_stride),\n",
    "      len(dense_1_units), len(activation_1_dense), len(learning_rate), len(Score))\n",
    "\n",
    "############# create data frame\n",
    "df_3c3p1f1d1d = pd.DataFrame(list(zip(conv_1_filter, conv_1_kernel, activation_1_conv, MaxPol_1_stride,\n",
    "                                      conv_2_filter, conv_2_kernel, activation_2_conv, MaxPol_2_stride,\n",
    "                                      conv_3_filter, conv_3_kernel, activation_3_conv, MaxPol_3_stride,\n",
    "                                      dense_1_units, activation_1_dense, learning_rate, Score)),\n",
    "               columns =['Conv1_filters', 'Conv1_kernel', 'Conv1_activation','Maxpol1_stride',\n",
    "                         'Conv2_filters', 'Conv2_kernel', 'Conv2_activation','Maxpol2_stride',\n",
    "                         'Conv3_filters', 'Conv3_kernel', 'Conv3_activation','Maxpol3_stride',\n",
    "                         'Dense1_units', 'Dense1_activation', 'learning_rate','Score'])\n",
    "############ Df head\n",
    "print(df_3c3p1f1d1d.shape)\n",
    "df_3c3p1f1d1d.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6)  Basic Model 3c3p1f2d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      "(30, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conv1_filters</th>\n",
       "      <th>Conv1_kernel</th>\n",
       "      <th>Conv1_activation</th>\n",
       "      <th>Maxpol1_stride</th>\n",
       "      <th>Conv2_filters</th>\n",
       "      <th>Conv2_kernel</th>\n",
       "      <th>Conv2_activation</th>\n",
       "      <th>Maxpol2_stride</th>\n",
       "      <th>Conv3_filters</th>\n",
       "      <th>Conv3_kernel</th>\n",
       "      <th>Conv3_activation</th>\n",
       "      <th>Maxpol3_stride</th>\n",
       "      <th>Dense1_units</th>\n",
       "      <th>Dense1_activation</th>\n",
       "      <th>Dense2_units</th>\n",
       "      <th>Dense2_activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>160</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9759036302566528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>tanh</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9759036302566528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>elu</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>relu</td>\n",
       "      <td>160</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9749768376350403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9731232523918152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9712696671485901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9712696671485901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>relu</td>\n",
       "      <td>96</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9703429341316223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9703429341316223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>relu</td>\n",
       "      <td>96</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9666357636451721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9657089710235596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Conv1_filters Conv1_kernel Conv1_activation Maxpol1_stride Conv2_filters  \\\n",
       "0            48            9              elu              4            48   \n",
       "1            48            7              elu              2            96   \n",
       "2            80            9              elu              6            32   \n",
       "3            64            3              elu              4            96   \n",
       "4            80            7             relu              4            64   \n",
       "5            80            7             relu              4            64   \n",
       "6            80            9              elu              4            64   \n",
       "7            80            5              elu              4            80   \n",
       "8            64            3              elu              4            96   \n",
       "9            80            5              elu              4            80   \n",
       "\n",
       "  Conv2_kernel Conv2_activation Maxpol2_stride Conv3_filters Conv3_kernel  \\\n",
       "0            3             tanh              2            80            3   \n",
       "1            5             relu              4            64            2   \n",
       "2            5              elu              2            48            2   \n",
       "3            5              elu              2            80            2   \n",
       "4            3             relu              2            96            3   \n",
       "5            3             relu              2            96            3   \n",
       "6            5             tanh              2            96            3   \n",
       "7            3             tanh              2            64            2   \n",
       "8            5              elu              2            80            2   \n",
       "9            3             tanh              2            64            2   \n",
       "\n",
       "  Conv3_activation Maxpol3_stride Dense1_units Dense1_activation Dense2_units  \\\n",
       "0             relu              2          160              relu          160   \n",
       "1             tanh              2           96              tanh          224   \n",
       "2             tanh              2          224              relu          160   \n",
       "3             relu              2          160              relu           96   \n",
       "4             relu              2          224              tanh           32   \n",
       "5             relu              2          224              tanh           32   \n",
       "6             relu              2          224              relu           96   \n",
       "7             tanh              2          224              tanh           32   \n",
       "8             relu              2          160              relu           96   \n",
       "9             tanh              2          224              tanh           32   \n",
       "\n",
       "  Dense2_activation learning_rate               Score  \n",
       "0              tanh        0.0001  0.9759036302566528  \n",
       "1              tanh         0.001  0.9759036302566528  \n",
       "2              tanh         0.001  0.9749768376350403  \n",
       "3              relu         0.001  0.9731232523918152  \n",
       "4              tanh         0.001  0.9712696671485901  \n",
       "5              tanh         0.001  0.9712696671485901  \n",
       "6              tanh         0.001  0.9703429341316223  \n",
       "7              relu         0.001  0.9703429341316223  \n",
       "8              relu         0.001  0.9666357636451721  \n",
       "9              relu         0.001  0.9657089710235596  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1_filter = []\n",
    "conv_1_kernel = []\n",
    "activation_1_conv = []\n",
    "MaxPol_1_stride = []\n",
    "conv_2_filter = []\n",
    "conv_2_kernel = []\n",
    "activation_2_conv = []\n",
    "MaxPol_2_stride = []\n",
    "conv_3_filter = []\n",
    "conv_3_kernel = []\n",
    "activation_3_conv = []\n",
    "MaxPol_3_stride = []\n",
    "dense_1_units = []\n",
    "activation_1_dense = []\n",
    "dense_2_units = []\n",
    "activation_2_dense = []\n",
    "learning_rate = []\n",
    "Score = []\n",
    "############ Reading text file\n",
    "with open('./Hyperparameter_Files/3c3p1f2d1d.txt') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "########### iterating over lines and saving hyper parameters  \n",
    "for line in lines:\n",
    "    if 'conv_1_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_filter.append(line.split()[1])\n",
    "    elif'conv_1_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_1_kernel.append(line.split()[1])\n",
    "    elif'activation_1_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_conv.append(line.split()[1])\n",
    "    elif'MaxPol_1_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_1_stride.append(line.split()[1])\n",
    "    elif 'conv_2_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_2_filter.append(line.split()[1])\n",
    "    elif'conv_2_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_2_kernel.append(line.split()[1])\n",
    "    elif'activation_2_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_2_conv.append(line.split()[1])\n",
    "    elif'MaxPol_2_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_2_stride.append(line.split()[1])\n",
    "    elif 'conv_3_filter:' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_3_filter.append(line.split()[1])\n",
    "    elif'conv_3_kernel' in line:\n",
    "        #print(line.split()[1])\n",
    "        conv_3_kernel.append(line.split()[1])\n",
    "    elif'activation_3_conv' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_3_conv.append(line.split()[1])\n",
    "    elif'MaxPol_3_stride' in line:\n",
    "        #print(line.split()[1])\n",
    "        MaxPol_3_stride.append(line.split()[1])\n",
    "    elif'dense_1_units' in line:\n",
    "        #print(line.split()[1])\n",
    "        dense_1_units.append(line.split()[1])\n",
    "    elif'activation_1_dense' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_1_dense.append(line.split()[1])\n",
    "    elif'dense_2_units' in line:\n",
    "        #print(line.split()[1])\n",
    "        dense_2_units.append(line.split()[1])\n",
    "    elif'activation_2_dense' in line:\n",
    "        #print(line.split()[1])\n",
    "        activation_2_dense.append(line.split()[1])\n",
    "    elif'learning_rate' in line:\n",
    "        #print(line.split()[1])\n",
    "        learning_rate.append(line.split()[1])\n",
    "    elif'Score' in line:\n",
    "        #print(line.split()[1])\n",
    "        Score.append(line.split()[1])\n",
    "############# Checking the consistency of the parameters\n",
    "print(len(conv_1_filter), len(conv_1_kernel), len(activation_1_conv), len(MaxPol_1_stride),\n",
    "      len(conv_2_filter), len(conv_2_kernel), len(activation_2_conv), len(MaxPol_2_stride),\n",
    "      len(conv_3_filter), len(conv_3_kernel), len(activation_3_conv), len(MaxPol_3_stride),\n",
    "      len(dense_1_units), len(activation_1_dense),\n",
    "      len(dense_2_units), len(activation_2_dense),len(learning_rate), len(Score))\n",
    "\n",
    "############# create data frame\n",
    "df_3c3p1f2d1d = pd.DataFrame(list(zip(conv_1_filter, conv_1_kernel, activation_1_conv, MaxPol_1_stride,\n",
    "                                      conv_2_filter, conv_2_kernel, activation_2_conv, MaxPol_2_stride,\n",
    "                                      conv_3_filter, conv_3_kernel, activation_3_conv, MaxPol_3_stride,\n",
    "                                      dense_1_units, activation_1_dense,\n",
    "                                      dense_2_units, activation_2_dense,learning_rate, Score)),\n",
    "               columns =['Conv1_filters', 'Conv1_kernel', 'Conv1_activation','Maxpol1_stride',\n",
    "                         'Conv2_filters', 'Conv2_kernel', 'Conv2_activation','Maxpol2_stride',\n",
    "                         'Conv3_filters', 'Conv3_kernel', 'Conv3_activation','Maxpol3_stride',\n",
    "                         'Dense1_units', 'Dense1_activation',\n",
    "                         'Dense2_units', 'Dense2_activation','learning_rate','Score'])\n",
    "############ Df head\n",
    "print(df_3c3p1f2d1d.shape)\n",
    "df_3c3p1f2d1d.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read HDF5 Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_many_hdf5(num_images, file_path):\n",
    "    \"\"\" Reads image from HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        num_images   number of images to read\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        images      images array, (N, 32, 32, 3) to be stored\n",
    "        labels      associated meta data, int label (N, 1)\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    file = h5py.File(file_path, \"r+\")\n",
    "\n",
    "    images = np.array(file[\"/images\"]).astype(\"uint8\")\n",
    "    labels = np.array(file[\"/meta\"]).astype(\"uint8\")\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on the best hyper parameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Basic Model 1c1p1f1d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1c1p1f1d1d():\n",
    "    \n",
    "    np.random.seed(786)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(7, 7), padding='same', activation='relu', input_shape=(190, 150,1)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(320, activation=tf.nn.relu, input_shape=(28500,)))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "    # We will now compile and print out a summary of our model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Basic Model 1c1p1f2d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1c1p1f2d1d():\n",
    "\n",
    "    np.random.seed(786)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=80, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(190, 150,1)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=8))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(28500,)))\n",
    "    model.add(tf.keras.layers.Dense(418, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "    # We will now compile and print out a summary of our model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Basic Model 2c2p1f1d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2c2p1f1d1d():\n",
    "    \n",
    "    np.random.seed(786)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(3, 3), padding='same', activation='tanh', input_shape=(190, 150,1)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=4))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=4))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(448, activation=tf.nn.tanh, input_shape=(28500,)))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "    # We will now compile and print out a summary of our model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Basic Model 2c2p1f2d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2c2p1f2d1d():\n",
    "    \n",
    "    np.random.seed(786)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(7, 7), padding='same', activation='relu', input_shape=(190, 150,1)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=6))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='elu'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(320, activation=tf.nn.tanh, input_shape=(28500,)))\n",
    "    model.add(tf.keras.layers.Dense(448, activation=tf.nn.tanh))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "    # We will now compile and print out a summary of our model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Basic Model 3c3p1f1d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3c3p1f1d1d():\n",
    "    \n",
    "    np.random.seed(786)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=80, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(190, 150,1)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=2))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=80, kernel_size=(5, 5), padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=2))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(448, activation=tf.nn.tanh, input_shape=(28500,)))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "    # We will now compile and print out a summary of our model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Basic Model 3c3p1f2d1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3c3p1f2d1d():\n",
    "    \n",
    "    np.random.seed(786)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5), padding='same', activation='tanh', input_shape=(190, 150,1)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=4))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=80, kernel_size=(3, 3), padding='same', activation='elu'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=4))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=48, kernel_size=(2, 2), padding='same', activation='tanh'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(strides=2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(28500,)))\n",
    "    model.add(tf.keras.layers.Dense(384, activation=tf.nn.tanh))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "    # We will now compile and print out a summary of our model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_accuracy_curves(history):\n",
    "    ############### printing accuracy and loss between the epoches #########\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'], label=\"Training\")\n",
    "    plt.plot(history.history['val_accuracy'], label =\"Validation\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'], label=\"Training\")\n",
    "    plt.plot(history.history['val_loss'], label =\"Validation\")\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ostu Binarisation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ostu_thd(XX):\n",
    "    rnd_images = []\n",
    "    for img in XX:\n",
    "        #img = rgb2gray(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Otsu's thresholding\n",
    "        ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        rnd_images.append(th2)\n",
    "    test_images = np.array(rnd_images)\n",
    "    \n",
    "    return test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split + Reshaping Data to adjust greyscal dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pre_process(X, y):\n",
    "    \n",
    "    # test_size is the test size of the total dataset, random_state controls the shuffling of data. same state returns same data always.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=786, stratify=y) \n",
    "    print(\"Total training intences: \" + str(len(y_train)))\n",
    "    print(\"Train Data:\" + str(np.unique(y_train, return_counts=True)))\n",
    "    print(\"Total testing intences: \" + str(len(y_test)))\n",
    "    print(\"Test Data:\" + str(np.unique(y_test, return_counts=True)))\n",
    "\n",
    "    print(\"Before Reshaping the shape of train and test dataset:\")\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    # reshape to be [samples][width][height][channels]\n",
    "    X_train = X_train.reshape((X_train.shape[0], 190, 150, 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], 190, 150, 1))\n",
    "    print(\"After Reshaping the shape of train and test dataset:\")\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    \n",
    "    # Convert the array to float32 as opposed to uint8\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # Convert the pixel values from integers between 0 and 255 to floats between 0 and 1\n",
    "    X_train /= 255\n",
    "    X_test /=  255\n",
    "\n",
    "    NUM_DIGITS = 2\n",
    "\n",
    "    print(\"Before\", y_train[0]) # The format of the labels before conversion\n",
    "\n",
    "    y_train  = tf.keras.utils.to_categorical(y_train, NUM_DIGITS)\n",
    "\n",
    "    print(\"After\", y_train[0]) # The format of the labels after conversion\n",
    "\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, NUM_DIGITS)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Execution Body\n",
    "## 1. Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total X intences: (5135, 190, 150, 3)\n",
      "Total y intences: 5135\n",
      "Total Non porosity images: 2578\n",
      "Total porosity images: 2557\n",
      "X Shape after Ostu Binarisation: (5135, 190, 150)\n",
      "Total training intences: 3594\n",
      "Train Data:(array([0, 1], dtype=uint8), array([1804, 1790], dtype=int64))\n",
      "Total testing intences: 1541\n",
      "Test Data:(array([0, 1], dtype=uint8), array([774, 767], dtype=int64))\n",
      "Before Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150)\n",
      "(1541, 190, 150)\n",
      "After Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150, 1)\n",
      "(1541, 190, 150, 1)\n",
      "Before 1\n",
      "After [0. 1.]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 190, 150, 64)      3200      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 95, 75, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 456000)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 320)               145920320 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 642       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,924,162\n",
      "Trainable params: 145,924,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[456000,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/sequential/dense/MatMul/MatMul_1\n (defined at D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_732]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/sequential/dense/MatMul/MatMul_1:\nIn[0] sequential/flatten/Reshape (defined at D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\layers\\core\\flatten.py:96)\t\nIn[1] gradient_tape/sequential/dense/ReluGrad:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Temp\\ipykernel_1188\\1875952324.py\", line 21, in <cell line: 21>\n>>>     history1 = model1.fit(X_train, y_train, epochs=20,verbose=1, validation_split=0.3)#, class_weight=my_class_weight)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m model1 \u001b[38;5;241m=\u001b[39m model_1c1p1f1d1d()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m############ Fit Model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#model.fit(samples_cnn, dataset.labels, epochs=epochs, batch_size=batch_size, verbose=1)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m history1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, class_weight=my_class_weight)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(history1)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m########### Evaluate model\u001b[39;00m\n",
      "File \u001b[1;32mD:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[456000,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/sequential/dense/MatMul/MatMul_1\n (defined at D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_732]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/sequential/dense/MatMul/MatMul_1:\nIn[0] sequential/flatten/Reshape (defined at D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\layers\\core\\flatten.py:96)\t\nIn[1] gradient_tape/sequential/dense/ReluGrad:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Temp\\ipykernel_1188\\1875952324.py\", line 21, in <cell line: 21>\n>>>     history1 = model1.fit(X_train, y_train, epochs=20,verbose=1, validation_split=0.3)#, class_weight=my_class_weight)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "############ read Dataset\n",
    "dir_file_path = \"D:/UoH_PhD_Exp/Data/Data_HDF/Porosity_Balanced_Data.h5\"\n",
    "X, y = read_many_hdf5(0,dir_file_path)\n",
    "print(\"Total X intences: \" + str(X.shape))\n",
    "print(\"Total y intences: \" + str(len(y)))\n",
    "my_class, my_count = np.unique(y, return_counts=True)\n",
    "print(\"Total Non porosity images: \" + str(my_count[0]))\n",
    "print(\"Total porosity images: \" + str(my_count[1]))\n",
    "\n",
    "############ Ostu Binarization\n",
    "X = ostu_thd(X)\n",
    "print(\"X Shape after Ostu Binarisation: \" + str(X.shape))\n",
    "############ Train-Test Split + Data Pre processing\n",
    "X_train, X_test, y_train, y_test = pre_process(X,y)\n",
    "############ Model\n",
    "model1 = model_1c1p1f1d1d()\n",
    "############ Fit Model\n",
    "#model.fit(samples_cnn, dataset.labels, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "history1 = model1.fit(X_train, y_train, epochs=20,verbose=1, validation_split=0.3)#, class_weight=my_class_weight)\n",
    "print(history1)\n",
    "########### Evaluate model\n",
    "loss1, accuracy1 = model1.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy1))\n",
    "print('Test loss: %.2f' % (loss1))\n",
    "########## Classification Report\n",
    "y_pred = model1.predict(X_test)\n",
    "y_actual = np.argmax(y_test,axis=1)\n",
    "print(y_actual[0:25])\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "print(y_pred[0:25])\n",
    "\n",
    "print(classification_report(y_actual,y_pred))\n",
    "print(confusion_matrix(y_actual,y_pred))\n",
    "print(accuracy_score(y_actual,y_pred))\n",
    "\n",
    "################# PLot Loss accuracy curves\n",
    "loss_accuracy_curves(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total X intences: (5135, 190, 150, 3)\n",
      "Total y intences: 5135\n",
      "Total Non porosity images: 2578\n",
      "Total porosity images: 2557\n",
      "X Shape after Ostu Binarisation: (5135, 190, 150)\n",
      "Total training intences: 3594\n",
      "Train Data:(array([0, 1], dtype=uint8), array([1804, 1790], dtype=int64))\n",
      "Total testing intences: 1541\n",
      "Test Data:(array([0, 1], dtype=uint8), array([774, 767], dtype=int64))\n",
      "Before Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150)\n",
      "(1541, 190, 150)\n",
      "After Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150, 1)\n",
      "(1541, 190, 150, 1)\n",
      "Before 1\n",
      "After [0. 1.]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 190, 150, 80)      2080      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 19, 80)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 36480)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               18678272  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 418)               214434    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 838       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,895,624\n",
      "Trainable params: 18,895,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.8453"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[10,80,190,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_1/conv2d_1/Conv2D\n (defined at D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\layers\\convolutional.py:231)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_2756]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_1/conv2d_1/Conv2D:\nIn[0] IteratorGetNext (defined at D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py:1355)\t\nIn[1] sequential_1/conv2d_1/Conv2D/ReadVariableOp:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Temp\\ipykernel_1188\\1653423558.py\", line 21, in <cell line: 21>\n>>>     history2 = model1.fit(X_train, y_train, batch_size=10, epochs=20,verbose=1, validation_split=0.3)#, class_weight=my_class_weight)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1252, in fit\n>>>     val_logs = self.evaluate(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1537, in evaluate\n>>>     tmp_logs = self.test_function(iterator)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step\n>>>     outputs = model.test_step(data)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1303, in test_step\n>>>     y_pred = self(x, training=False)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 246, in call\n>>>     outputs = self.convolution_op(inputs, self.kernel)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 231, in convolution_op\n>>>     return tf.nn.convolution(\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m model1 \u001b[38;5;241m=\u001b[39m model_1c1p1f2d1d()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m############ Fit Model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#model.fit(samples_cnn, dataset.labels, epochs=epochs, batch_size=batch_size, verbose=1)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m history2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, class_weight=my_class_weight)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(history2)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m########### Evaluate model\u001b[39;00m\n",
      "File \u001b[1;32mD:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[10,80,190,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_1/conv2d_1/Conv2D\n (defined at D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\layers\\convolutional.py:231)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_2756]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_1/conv2d_1/Conv2D:\nIn[0] IteratorGetNext (defined at D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py:1355)\t\nIn[1] sequential_1/conv2d_1/Conv2D/ReadVariableOp:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\ayub_\\AppData\\Local\\Temp\\ipykernel_1188\\1653423558.py\", line 21, in <cell line: 21>\n>>>     history2 = model1.fit(X_train, y_train, batch_size=10, epochs=20,verbose=1, validation_split=0.3)#, class_weight=my_class_weight)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1252, in fit\n>>>     val_logs = self.evaluate(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1537, in evaluate\n>>>     tmp_logs = self.test_function(iterator)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step\n>>>     outputs = model.test_step(data)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1303, in test_step\n>>>     y_pred = self(x, training=False)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 246, in call\n>>>     outputs = self.convolution_op(inputs, self.kernel)\n>>> \n>>>   File \"D:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 231, in convolution_op\n>>>     return tf.nn.convolution(\n>>> "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "############ read Dataset\n",
    "dir_file_path = \"D:/UoH_PhD_Exp/Data/Data_HDF/Porosity_Balanced_Data.h5\"\n",
    "X, y = read_many_hdf5(0,dir_file_path)\n",
    "print(\"Total X intences: \" + str(X.shape))\n",
    "print(\"Total y intences: \" + str(len(y)))\n",
    "my_class, my_count = np.unique(y, return_counts=True)\n",
    "print(\"Total Non porosity images: \" + str(my_count[0]))\n",
    "print(\"Total porosity images: \" + str(my_count[1]))\n",
    "\n",
    "############ Ostu Binarization\n",
    "X = ostu_thd(X)\n",
    "print(\"X Shape after Ostu Binarisation: \" + str(X.shape))\n",
    "############ Train-Test Split + Data Pre processing\n",
    "X_train, X_test, y_train, y_test = pre_process(X,y)\n",
    "############ Model\n",
    "model1 = model_1c1p1f2d1d()\n",
    "############ Fit Model\n",
    "#model.fit(samples_cnn, dataset.labels, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "history2 = model1.fit(X_train, y_train, batch_size=10, epochs=20,verbose=1, validation_split=0.3)#, class_weight=my_class_weight)\n",
    "print(history2)\n",
    "########### Evaluate model\n",
    "loss1, accuracy1 = model1.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy1))\n",
    "print('Test loss: %.2f' % (loss1))\n",
    "########## Classification Report\n",
    "y_pred = model1.predict(X_test)\n",
    "y_actual = np.argmax(y_test,axis=1)\n",
    "print(y_actual[0:25])\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "print(y_pred[0:25])\n",
    "\n",
    "print(classification_report(y_actual,y_pred))\n",
    "print(confusion_matrix(y_actual,y_pred))\n",
    "print(accuracy_score(y_actual,y_pred))\n",
    "\n",
    "################# PLot Loss accuracy curves\n",
    "loss_accuracy_curves(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total X intences: (5135, 190, 150, 3)\n",
      "Total y intences: 5135\n",
      "Total Non porosity images: 2578\n",
      "Total porosity images: 2557\n",
      "X Shape after Ostu Binarisation: (5135, 190, 150)\n",
      "Total training intences: 3594\n",
      "Train Data:(array([0, 1], dtype=uint8), array([1804, 1790], dtype=int64))\n",
      "Total testing intences: 1541\n",
      "Test Data:(array([0, 1], dtype=uint8), array([774, 767], dtype=int64))\n",
      "Before Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150)\n",
      "(1541, 190, 150)\n",
      "After Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150, 1)\n",
      "(1541, 190, 150, 1)\n",
      "Before 1\n",
      "After [0. 1.]\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 190, 150, 96)      960       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 48, 38, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 48, 38, 96)        83040     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 10, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 11520)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 448)               5161408   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 898       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,246,306\n",
      "Trainable params: 5,246,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m model1 \u001b[38;5;241m=\u001b[39m model_2c2p1f1d1d()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m############ Fit Model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#model.fit(samples_cnn, dataset.labels, epochs=epochs, batch_size=batch_size, verbose=1)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m history3 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, class_weight=my_class_weight)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(history3)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m########### Evaluate model\u001b[39;00m\n",
      "File \u001b[1;32mD:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    105\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "############ read Dataset\n",
    "dir_file_path = \"D:/UoH_PhD_Exp/Data/Data_HDF/Porosity_Balanced_Data.h5\"\n",
    "X, y = read_many_hdf5(0,dir_file_path)\n",
    "print(\"Total X intences: \" + str(X.shape))\n",
    "print(\"Total y intences: \" + str(len(y)))\n",
    "my_class, my_count = np.unique(y, return_counts=True)\n",
    "print(\"Total Non porosity images: \" + str(my_count[0]))\n",
    "print(\"Total porosity images: \" + str(my_count[1]))\n",
    "\n",
    "############ Ostu Binarization\n",
    "X = ostu_thd(X)\n",
    "print(\"X Shape after Ostu Binarisation: \" + str(X.shape))\n",
    "############ Train-Test Split + Data Pre processing\n",
    "X_train, X_test, y_train, y_test = pre_process(X,y)\n",
    "############ Model\n",
    "model1 = model_2c2p1f1d1d()\n",
    "############ Fit Model\n",
    "#model.fit(samples_cnn, dataset.labels, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "history3 = model1.fit(X_train, y_train, batch_size=10, epochs=20,verbose=1, validation_split=0.3)#, class_weight=my_class_weight)\n",
    "print(history3)\n",
    "########### Evaluate model\n",
    "loss1, accuracy1 = model1.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy1))\n",
    "print('Test loss: %.2f' % (loss1))\n",
    "########## Classification Report\n",
    "y_pred = model1.predict(X_test)\n",
    "y_actual = np.argmax(y_test,axis=1)\n",
    "print(y_actual[0:25])\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "print(y_pred[0:25])\n",
    "\n",
    "print(classification_report(y_actual,y_pred))\n",
    "print(confusion_matrix(y_actual,y_pred))\n",
    "print(accuracy_score(y_actual,y_pred))\n",
    "\n",
    "################# PLot Loss accuracy curves\n",
    "loss_accuracy_curves(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total X intences: (5135, 190, 150, 3)\n",
      "Total y intences: 5135\n",
      "Total Non porosity images: 2578\n",
      "Total porosity images: 2557\n",
      "X Shape after Ostu Binarisation: (5135, 190, 150)\n",
      "Total training intences: 3594\n",
      "Train Data:(array([0, 1], dtype=uint8), array([1804, 1790], dtype=int64))\n",
      "Total testing intences: 1541\n",
      "Test Data:(array([0, 1], dtype=uint8), array([774, 767], dtype=int64))\n",
      "Before Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150)\n",
      "(1541, 190, 150)\n",
      "After Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150, 1)\n",
      "(1541, 190, 150, 1)\n",
      "Before 1\n",
      "After [0. 1.]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 190, 150, 64)      3200      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 32, 25, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 25, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12288)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 320)               3932480   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 448)               143808    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 898       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,117,314\n",
      "Trainable params: 4,117,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m model1 \u001b[38;5;241m=\u001b[39m model_2c2p1f2d1d()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m############ Fit Model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#model.fit(samples_cnn, dataset.labels, epochs=epochs, batch_size=batch_size, verbose=1)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m history4 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, class_weight=my_class_weight)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(history4)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m########### Evaluate model\u001b[39;00m\n",
      "File \u001b[1;32mD:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    105\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "############ read Dataset\n",
    "dir_file_path = \"D:/UoH_PhD_Exp/Data/Data_HDF/Porosity_Balanced_Data.h5\"\n",
    "X, y = read_many_hdf5(0,dir_file_path)\n",
    "print(\"Total X intences: \" + str(X.shape))\n",
    "print(\"Total y intences: \" + str(len(y)))\n",
    "my_class, my_count = np.unique(y, return_counts=True)\n",
    "print(\"Total Non porosity images: \" + str(my_count[0]))\n",
    "print(\"Total porosity images: \" + str(my_count[1]))\n",
    "\n",
    "############ Ostu Binarization\n",
    "X = ostu_thd(X)\n",
    "print(\"X Shape after Ostu Binarisation: \" + str(X.shape))\n",
    "############ Train-Test Split + Data Pre processing\n",
    "X_train, X_test, y_train, y_test = pre_process(X,y)\n",
    "############ Model\n",
    "model1 = model_2c2p1f2d1d()\n",
    "############ Fit Model\n",
    "#model.fit(samples_cnn, dataset.labels, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "history4 = model1.fit(X_train, y_train, batch_size=10, epochs=20,verbose=1, validation_split=0.3)#, class_weight=my_class_weight)\n",
    "print(history4)\n",
    "########### Evaluate model\n",
    "loss1, accuracy1 = model1.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy1))\n",
    "print('Test loss: %.2f' % (loss1))\n",
    "########## Classification Report\n",
    "y_pred = model1.predict(X_test)\n",
    "y_actual = np.argmax(y_test,axis=1)\n",
    "print(y_actual[0:25])\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "print(y_pred[0:25])\n",
    "\n",
    "print(classification_report(y_actual,y_pred))\n",
    "print(confusion_matrix(y_actual,y_pred))\n",
    "print(accuracy_score(y_actual,y_pred))\n",
    "\n",
    "################# PLot Loss accuracy curves\n",
    "loss_accuracy_curves(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total X intences: (5135, 190, 150, 3)\n",
      "Total y intences: 5135\n",
      "Total Non porosity images: 2578\n",
      "Total porosity images: 2557\n",
      "X Shape after Ostu Binarisation: (5135, 190, 150)\n",
      "Total training intences: 3594\n",
      "Train Data:(array([0, 1], dtype=uint8), array([1804, 1790], dtype=int64))\n",
      "Total testing intences: 1541\n",
      "Test Data:(array([0, 1], dtype=uint8), array([774, 767], dtype=int64))\n",
      "Before Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150)\n",
      "(1541, 190, 150)\n",
      "After Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150, 1)\n",
      "(1541, 190, 150, 1)\n",
      "Before 1\n",
      "After [0. 1.]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[26496,448] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m pre_process(X,y)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m############ Model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_3c3p1f1d1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m############ Fit Model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#model.fit(samples_cnn, dataset.labels, epochs=epochs, batch_size=batch_size, verbose=1)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m history5 \u001b[38;5;241m=\u001b[39m model1\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\u001b[38;5;66;03m#, class_weight=my_class_weight)\u001b[39;00m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mmodel_3c3p1f1d1d\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPool2D(strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten())\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m448\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m2\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# We will now compile and print out a summary of our model\u001b[39;00m\n",
      "File \u001b[1;32mD:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mD:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\UoH_PhD_Exp\\my_ve_env\\lib\\site-packages\\keras\\backend.py:1831\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m   1828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator:\n\u001b[0;32m   1829\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m   1830\u001b[0m       shape\u001b[38;5;241m=\u001b[39mshape, minval\u001b[38;5;241m=\u001b[39mminval, maxval\u001b[38;5;241m=\u001b[39mmaxval, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m-> 1831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_legacy_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[26496,448] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "############ read Dataset\n",
    "dir_file_path = \"D:/UoH_PhD_Exp/Data/Data_HDF/Porosity_Balanced_Data.h5\"\n",
    "X, y = read_many_hdf5(0,dir_file_path)\n",
    "print(\"Total X intences: \" + str(X.shape))\n",
    "print(\"Total y intences: \" + str(len(y)))\n",
    "my_class, my_count = np.unique(y, return_counts=True)\n",
    "print(\"Total Non porosity images: \" + str(my_count[0]))\n",
    "print(\"Total porosity images: \" + str(my_count[1]))\n",
    "\n",
    "############ Ostu Binarization\n",
    "X = ostu_thd(X)\n",
    "print(\"X Shape after Ostu Binarisation: \" + str(X.shape))\n",
    "############ Train-Test Split + Data Pre processing\n",
    "X_train, X_test, y_train, y_test = pre_process(X,y)\n",
    "############ Model\n",
    "model1 = model_3c3p1f1d1d()\n",
    "############ Fit Model\n",
    "#model.fit(samples_cnn, dataset.labels, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "history5 = model1.fit(X_train, y_train, batch_size=10, epochs=20,verbose=1, validation_split=0.3)#, class_weight=my_class_weight)\n",
    "print(history5)\n",
    "########### Evaluate model\n",
    "loss1, accuracy1 = model1.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy1))\n",
    "print('Test loss: %.2f' % (loss1))\n",
    "########## Classification Report\n",
    "y_pred = model1.predict(X_test)\n",
    "y_actual = np.argmax(y_test,axis=1)\n",
    "print(y_actual[0:25])\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "print(y_pred[0:25])\n",
    "\n",
    "print(classification_report(y_actual,y_pred))\n",
    "print(confusion_matrix(y_actual,y_pred))\n",
    "print(accuracy_score(y_actual,y_pred))\n",
    "\n",
    "################# PLot Loss accuracy curves\n",
    "loss_accuracy_curves(history5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total X intences: (5135, 190, 150, 3)\n",
      "Total y intences: 5135\n",
      "Total Non porosity images: 2578\n",
      "Total porosity images: 2557\n",
      "X Shape after Ostu Binarisation: (5135, 190, 150)\n",
      "Total training intences: 3594\n",
      "Train Data:(array([0, 1], dtype=uint8), array([1804, 1790], dtype=int64))\n",
      "Total testing intences: 1541\n",
      "Test Data:(array([0, 1], dtype=uint8), array([774, 767], dtype=int64))\n",
      "Before Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150)\n",
      "(1541, 190, 150)\n",
      "After Reshaping the shape of train and test dataset:\n",
      "(3594, 190, 150, 1)\n",
      "(1541, 190, 150, 1)\n",
      "Before 1\n",
      "After [0. 1.]\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 190, 150, 32)      832       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 48, 38, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 48, 38, 80)        23120     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 12, 10, 80)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 12, 10, 48)        15408     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 6, 5, 48)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1440)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 512)               737792    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 384)               196992    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 770       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 974,914\n",
      "Trainable params: 974,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 7s 24ms/step - loss: 0.2737 - accuracy: 0.8863 - val_loss: 0.1095 - val_accuracy: 0.9583\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 5s 22ms/step - loss: 0.1114 - accuracy: 0.9662 - val_loss: 0.2747 - val_accuracy: 0.9314\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 5s 22ms/step - loss: 0.0801 - accuracy: 0.9746 - val_loss: 0.0884 - val_accuracy: 0.9731\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 6s 22ms/step - loss: 0.0495 - accuracy: 0.9853 - val_loss: 0.1615 - val_accuracy: 0.9601\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 6s 22ms/step - loss: 0.0571 - accuracy: 0.9817 - val_loss: 0.0969 - val_accuracy: 0.9768\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 6s 22ms/step - loss: 0.0388 - accuracy: 0.9881 - val_loss: 0.0996 - val_accuracy: 0.9713\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 6s 22ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0954 - val_accuracy: 0.9768\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 6s 22ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.0916 - val_accuracy: 0.9796\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 6s 22ms/step - loss: 0.0405 - accuracy: 0.9873 - val_loss: 1.0835 - val_accuracy: 0.7025\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 6s 22ms/step - loss: 0.0514 - accuracy: 0.9845 - val_loss: 0.1077 - val_accuracy: 0.9731\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 6s 22ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.2012 - val_accuracy: 0.9666\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 6s 22ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.1210 - val_accuracy: 0.9750\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 6s 22ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.0946 - val_accuracy: 0.9731\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 6s 23ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.1022 - val_accuracy: 0.9759\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 6s 23ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.1141 - val_accuracy: 0.9778\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 6s 23ms/step - loss: 3.1584e-04 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9787\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 6s 23ms/step - loss: 6.7736e-05 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9787\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 6s 23ms/step - loss: 4.1931e-05 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9787\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 6s 23ms/step - loss: 2.8467e-05 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9787\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 6s 23ms/step - loss: 2.1174e-05 - accuracy: 1.0000 - val_loss: 0.1728 - val_accuracy: 0.9787\n",
      "<keras.callbacks.History object at 0x000002498A0D4760>\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.2390 - accuracy: 0.9650\n",
      "Test accuracy: 0.96\n",
      "Test loss: 0.24\n",
      "[1 0 1 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 1 0 0 0]\n",
      "[1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       774\n",
      "           1       0.97      0.96      0.96       767\n",
      "\n",
      "    accuracy                           0.96      1541\n",
      "   macro avg       0.97      0.96      0.96      1541\n",
      "weighted avg       0.97      0.96      0.96      1541\n",
      "\n",
      "[[754  20]\n",
      " [ 34 733]]\n",
      "0.9649578195976638\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "############ read Dataset\n",
    "dir_file_path = \"D:/UoH_PhD_Exp/Data/Data_HDF/Porosity_Balanced_Data.h5\"\n",
    "X, y = read_many_hdf5(0,dir_file_path)\n",
    "print(\"Total X intences: \" + str(X.shape))\n",
    "print(\"Total y intences: \" + str(len(y)))\n",
    "my_class, my_count = np.unique(y, return_counts=True)\n",
    "print(\"Total Non porosity images: \" + str(my_count[0]))\n",
    "print(\"Total porosity images: \" + str(my_count[1]))\n",
    "\n",
    "############ Ostu Binarization\n",
    "X = ostu_thd(X)\n",
    "print(\"X Shape after Ostu Binarisation: \" + str(X.shape))\n",
    "############ Train-Test Split + Data Pre processing\n",
    "X_train, X_test, y_train, y_test = pre_process(X,y)\n",
    "############ Model\n",
    "model1 = model_3c3p1f2d1d()\n",
    "############ Fit Model\n",
    "#model.fit(samples_cnn, dataset.labels, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "history6 = model1.fit(X_train, y_train, batch_size=10, epochs=20,verbose=1, validation_split=0.3)#, class_weight=my_class_weight)\n",
    "print(history6)\n",
    "########### Evaluate model\n",
    "loss1, accuracy1 = model1.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy1))\n",
    "print('Test loss: %.2f' % (loss1))\n",
    "########## Classification Report\n",
    "y_pred = model1.predict(X_test)\n",
    "y_actual = np.argmax(y_test,axis=1)\n",
    "print(y_actual[0:25])\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "print(y_pred[0:25])\n",
    "\n",
    "print(classification_report(y_actual,y_pred))\n",
    "print(confusion_matrix(y_actual,y_pred))\n",
    "print(accuracy_score(y_actual,y_pred))\n",
    "\n",
    "################# PLot Loss accuracy curves\n",
    "loss_accuracy_curves(history6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ve_env",
   "language": "python",
   "name": "my_ve_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
